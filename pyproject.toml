[project]
name = "textual-chat"
version = "0.1.0"
description = "LLM chat for humans. Add AI to your Textual app in 6 lines."
readme = "README.md"
requires-python = ">=3.10"
license = "MIT"
keywords = ["textual", "tui", "llm", "chat", "ai"]
dependencies = [
    "textual>=0.85.0",
    "litellm>=1.0.0",
    "httpx>=0.27.0",
    "textual-golden",
]

[tool.uv.sources]
textual-golden = { path = "../textual-golden", editable = true }

[project.optional-dependencies]
mcp = [
    "fastmcp>=2.0.0",
]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.8.0",
    "fastmcp>=2.0.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/textual_chat"]

[dependency-groups]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.8.0",
    "fastmcp>=2.0.0",
]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "UP"]
